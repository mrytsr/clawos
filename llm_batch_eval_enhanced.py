#!/usr/bin/env python3
"""
å¤§æ¨¡å‹æ™ºå•†è¯„æµ‹è„šæœ¬ - å¼ºåŒ–ç‰ˆï¼ˆ60é¢˜ï¼‰- å¸¦è¯¦ç»†æ—¥å¿—
"""

import requests
import json
import time
import sys
from typing import List, Dict, Tuple
from datetime import datetime

print(f"[{datetime.now().strftime('%H:%M:%S')}] [INIT] è„šæœ¬å¯åŠ¨...", flush=True)

# ============ å¼ºåŒ–ç‰ˆé¢˜ç›®åº“ ============
print(f"[{datetime.now().strftime('%H:%M:%S')}] [INIT] åŠ è½½é¢˜ç›®åº“...", flush=True)

REASONING_QUESTIONS = [
    {"question": "è§£æ–¹ç¨‹ç»„ï¼š2x+3y-z=10, x-y+2z=-5, 3x+2y+z=8ã€‚è¯·ç”¨çŸ©é˜µæ¶ˆå…ƒæ³•æ±‚è§£ã€‚", "answer_type": "math_system"},
    {"question": "è®¡ç®—å®šç§¯åˆ†ï¼šâˆ«(0åˆ°Ï€) xÂ·sin(x) dxï¼Œç»™å‡ºè¯¦ç»†æ­¥éª¤ã€‚", "answer_type": "calculus"},
    {"question": "æ•°åˆ—aâ‚=1,aâ‚‚=3,aâ‚™=2aâ‚™â‚‹â‚+aâ‚™â‚‹â‚‚ã€‚æ±‚aâ‚†å¹¶è¯æ˜é€šé¡¹å…¬å¼ã€‚", "answer_type": "sequence"},
    {"question": "æ¦‚ç‡é¢˜ï¼šè¢‹ä¸­æœ‰5çº¢çƒã€3è“çƒã€2ç»¿çƒã€‚è¿ç»­æŠ½3æ¬¡ï¼ˆä¸æ”¾å›ï¼‰ï¼Œæ±‚è‡³å°‘æŠ½åˆ°2ä¸ªçº¢çƒçš„æ¦‚ç‡ã€‚", "answer_type": "probability"},
    {"question": "äº”äººè·‘æ­¥ï¼šAåœ¨Bå‰é¢ï¼ŒCç¬¬ä¸‰ï¼ŒDç´§è·ŸEåï¼ŒBä¸åœ¨æœ€åã€‚è¯·æ¨æ–­æ‰€æœ‰åæ¬¡ï¼Œåˆ—å‡ºæ‰€æœ‰å¯èƒ½ã€‚", "answer_type": "logical_race"},
    {"question": "é€»è¾‘ï¼šå¦‚æœä¸‹é›¨åˆ™åœ°æ¹¿ã€‚åœ°æ˜¯æ¹¿çš„ã€‚èƒ½å¾—å‡ºä¸‹é›¨äº†å—ï¼Ÿåˆ†æå……åˆ†æ¡ä»¶å’Œå¿…è¦æ¡ä»¶çš„åŒºåˆ«ã€‚", "answer_type": "logical_conditional"},
    {"question": "åˆ¤æ–­æ¨ç†ï¼šæ‰€æœ‰å“ºä¹³åŠ¨ç‰©æ’æ¸©ï¼Œé²¸é±¼æ˜¯å“ºä¹³åŠ¨ç‰©ï¼Œæ‰€ä»¥é²¸é±¼æ’æ¸©ã€‚ç”¨ä¸‰æ®µè®ºè§„åˆ™åˆ†æã€‚", "answer_type": "syllogism"},
    {"question": "æ’é™¤æ³•ï¼šä¸‰ç›’è£…è‹¹æœã€æ©™å­ã€‚ç¬¬ä¸€äººè¯´ç¬¬ä¸€ç›’æ˜¯è‹¹æœï¼ˆå‡ï¼‰ï¼Œç¬¬äºŒäººè¯´ç¬¬ä¸€ç›’æ˜¯æ©™å­ï¼ˆå‡ï¼‰ã€‚æ¨æ–­å„ç›’å­ã€‚", "answer_type": "elimination"},
    {"question": "æ¡ä»¶æ‚–è®ºï¼šå¦‚æœè¿™å¥è¯æ˜¯çœŸï¼Œä½ ç»™æˆ‘100å…ƒï¼›æ˜¯å‡ï¼Œä½ ä¸ç”¨ç»™æˆ‘100å…ƒã€‚åˆ†æè¿™ä¸ªæ‚–è®ºçš„é€»è¾‘ç»“æ„ã€‚", "answer_type": "paradox"},
    {"question": "é‡åŒ–é€»è¾‘ï¼šç”¨è°“è¯é€»è¾‘è¡¨ç¤º'æ‰€æœ‰å­¦ç”Ÿéƒ½è‡³å°‘æœ‰ä¸€é—¨è¯¾ä¸åŠæ ¼'ï¼Œå¹¶ç»™å‡ºå¦å®šå‘½é¢˜ã€‚", "answer_type": "predicate_logic"},
    {"question": "TSPé—®é¢˜ï¼š4åŸAã€Bã€Cã€Dã€‚è·ç¦»ï¼šA-B=10,A-C=15,A-D=20,B-C=35,B-D=25,C-D=30ã€‚ç”¨æœ€è¿‘é‚»ç®—æ³•æ±‚è¿‘ä¼¼æœ€ä¼˜è·¯å¾„ã€‚", "answer_type": "tsp"},
    {"question": "èƒŒåŒ…é—®é¢˜ï¼šç‰©å“é‡é‡[2,3,4,5]ï¼Œä»·å€¼[3,4,5,6]ï¼ŒèƒŒåŒ…å®¹é‡8ã€‚ç”¨åŠ¨æ€è§„åˆ’æ±‚æœ€å¤§ä»·å€¼ï¼Œå±•ç¤ºè¡¨æ ¼è¿‡ç¨‹ã€‚", "answer_type": "knapsack"},
    {"question": "é¡¹ç›®æ’ç¨‹ï¼šä»»åŠ¡A(3å¤©)â†’B(2å¤©)ã€C(4å¤©)å¹¶è¡Œâ†’D(2å¤©éœ€Bã€Cå®Œæˆ)ã€‚ç»˜åˆ¶ç”˜ç‰¹å›¾ï¼Œè®¡ç®—æœ€çŸ­å®Œæˆæ—¶é—´ã€‚", "answer_type": "scheduling"},
    {"question": "èµ„æºåˆ†é…ï¼šå…¬å¸3é¡¹ç›®ï¼Œé¢„ç®—100ä¸‡ã€‚æ”¶ç›Š[30,50,40]ï¼Œé£é™©[0.2,0.5,0.3]ã€‚ç”¨æ•´æ•°è§„åˆ’æ‰¾é£é™©æœ€å°åŒ–ä¸”æ”¶ç›Šæœ€å¤§åŒ–æ–¹æ¡ˆã€‚", "answer_type": "optimization"},
    {"question": "å€’æ°´é—®é¢˜ï¼š5å‡å’Œ3å‡å®¹å™¨ï¼Œæ— åˆ»åº¦ã€‚ç²¾ç¡®é‡å‡º4å‡æ°´ï¼Œç»™å‡ºæ­¥éª¤å¹¶è¯æ˜ã€‚", "answer_type": "water_puzzle"},
    {"question": "æ£‹ç›˜æ¨ç†ï¼šå›½é™…è±¡æ£‹é©¬ä»ä»»æ„ä½ç½®å‡ºå‘ï¼Œ3æ­¥å†…èƒ½åˆ°è¾¾ä»»æ„ä½ç½®å—ï¼Ÿè¯·æ•°å­¦è¯æ˜ã€‚", "answer_type": "chess_knight"},
    {"question": "ç»†èŒåˆ†è£‚ï¼šæ¯20åˆ†é’Ÿåˆ†è£‚ä¸€æ¬¡ã€‚åˆå§‹1ä¸ªï¼Œ4å°æ—¶åæœ‰å¤šå°‘ï¼Ÿç”¨æŒ‡æ•°å¢é•¿æ¨¡å‹è®¡ç®—ã€‚", "answer_type": "exponential"},
    {"question": "å¸½å­é¢œè‰²ï¼š3äººæ’ä¸€åˆ—ï¼Œå„çœ‹å‰é¢äººå¸½ã€‚3é¡¶2ç™½1é»‘ã€‚ä»æœ€åä¸€äººå¼€å§‹é—®æ˜¯å¦çŸ¥è‡ªå·±é¢œè‰²ã€‚åˆ†ææ¯ä¸ªäººæ¨ç†ã€‚", "answer_type": "hat_problem"},
    {"question": "ç”µæ¢¯ç­‰å¾…ï¼š10æ¥¼ï¼Œç”µæ¢¯åœ¨3æ¥¼ã€‚ç”µæ¢¯ä¸Šå‡0.5å±‚/ç§’ï¼Œå¯åŠ¨/åœæ­¢å„2ç§’ã€‚æ­¥è¡Œæ¯å±‚5ç§’ã€‚è®¡ç®—å“ªä¸ªæ›´å¿«åˆ°1æ¥¼ã€‚", "answer_type": "realworld_math"},
    {"question": "å¯†ç ç ´è§£ï¼š4ä½æ•°å­—ã€‚æ¡ä»¶ï¼šç¬¬ä¸€ä½=ç¬¬äºŒä½+1ï¼Œç¬¬äºŒä½Ã—ç¬¬ä¸‰ä½=24ï¼Œç¬¬ä¸‰ä½=ç¬¬å››ä½-2ã€‚æ‰¾å‡ºæ‰€æœ‰å¯èƒ½å¯†ç ã€‚", "answer_type": "constraint_solving"},
]

LANGUAGE_QUESTIONS = [
    {"question": "è¯­æ³•çº é”™ï¼ˆ5å¤„ï¼‰ï¼š'The committee have made their decision yesterday. Each members was asked to submit their opinion. The data which was collected by them were analyzed careful. Neither the manager nor the workers was available. More information are needed.'", "answer_type": "grammar_error"},
    {"question": "åŒä¹‰æ”¹å†™ï¼šç®€åŒ–ä¸º3ç§ä¸åŒé£æ ¼ã€‚'Although the company had been experiencing significant financial difficulties for several years, and despite the recommendations of several consultants to file for bankruptcy, the CEO, who had personally invested his entire life savings into the venture, decided to continue operations.'", "answer_type": "paraphrase"},
    {"question": "è¯ä¹‰è¾¨æå¡«ç©ºï¼š1. The economy has _______ (affected/effected) by inflation. 2. His _______ (continuous/continual) talking annoyed everyone. 3. The _______ (principal/principle) reason for leaving was money.", "answer_type": "vocab_distinction"},
    {"question": "ä»å¥è½¬æ¢ï¼šæ”¹å†™ä¸ºç®€å•å¥ã€å¹¶åˆ—å¥ã€å®šè¯­ä»å¥ä¸‰ç§å½¢å¼ã€‚'Because the experiment was successful, the scientist decided to publish the results immediately after verifying the data one more time.'", "answer_type": "clause_transformation"},
    {"question": "æ—¶æ€ç»¼åˆï¼šç”¨8ç§ä¸åŒæ—¶æ€ç¿»è¯‘'æˆ‘æ¯å¤©å­¦ä¹ è‹±è¯­'ã€‚", "answer_type": "tense_synthesis"},
    {"question": "é˜…è¯»ç†è§£ï¼šClimate change impacts through extreme weather, biodiversity loss, sea-level rise. Paris Agreement aims 1.5Â°C limit. Current commitments = 2.7Â°C by 2100. 'ambition gap' needs enhanced action. é—®é¢˜ï¼š1. 'ambition gap'æŒ‡ä»€ä¹ˆï¼Ÿ2. ç¼©å°å·®è·éœ€ä»€ä¹ˆæ¡ä»¶ï¼Ÿ3. å¯æ¨æ–­ä»€ä¹ˆï¼Ÿ", "answer_type": "academic_reading"},
    {"question": "æ–°é—»é˜…è¯»ï¼šæŸç§‘æŠ€å…¬å¸è®¡åˆ’5å¹´åœ¨AIé¢†åŸŸæŠ•100äº¿ç¾å…ƒã€‚CEOï¼šç”¨äºç ”å‘æ–°ä¸€ä»£AIèŠ¯ç‰‡ã€‚åˆ†æå¸ˆï¼šå¸‚åœºç«äº‰æ¿€çƒˆï¼Œå•†ä¸šåŒ–é¢ä¸´æŒ‘æˆ˜ã€‚é—®é¢˜ï¼š1. æŠ•èµ„è®¡åˆ’ï¼Ÿ2. CEOä¹è§‚åŸºäºï¼Ÿ3. åˆ†æå¸ˆè°¨æ…ç†ç”±ï¼Ÿ4. æ•´ä½“åŸºè°ƒï¼Ÿ", "answer_type": "news_reading"},
    {"question": "æ³•å¾‹é˜…è¯»ï¼šã€ŠåŠ³åŠ¨åˆåŒæ³•ã€‹ç¬¬38æ¡ï¼šæœªæä¾›åŠ³åŠ¨ä¿æŠ¤ã€æœªæ”¯ä»˜åŠ³åŠ¨æŠ¥é…¬ã€æœªç¼´çº³ç¤¾ä¿ã€è§„ç« åˆ¶åº¦æŸå®³åŠ³åŠ¨è€…æƒç›Šçš„ï¼ŒåŠ³åŠ¨è€…å¯è§£é™¤åˆåŒã€‚é—®é¢˜ï¼š1. å‡ ä¸ªæƒ…å½¢ï¼Ÿ2. æœªç¼´ç¤¾ä¿æ˜¯å¦ï¼Ÿ3. 'åŠ³åŠ¨ä¿æŠ¤'æŒ‡ä»€ä¹ˆï¼Ÿ", "answer_type": "legal_reading"},
    {"question": "å›¾è¡¨åˆ†æï¼š2020-2024å¹´å­£åº¦è¥æ”¶ï¼šQ1:120,135,128,142,155 Q2:145,150,138,160,168 Q3:130,142,155,152,175 Q4:160,175,168,185,195 é—®é¢˜ï¼š1. å“ªå¹´Q3åŒæ¯”å¢é•¿æœ€å¤§ï¼Ÿ2. é¢„æµ‹2025å…¨å¹´ 3. æ•´ä½“è¶‹åŠ¿ï¼Ÿ", "answer_type": "data_reading"},
    {"question": "å¤šæ–‡æœ¬æ¯”è¾ƒï¼šæ–‡æœ¬Aï¼šç¤¾äº¤åª’ä½“å¯¹é’å°‘å¹´æœ‰è´Ÿé¢å½±å“ï¼Œè¶…3å°æ—¶ä½¿ç”¨é£é™©å¢60%ã€‚æ–‡æœ¬Bï¼šç¤¾äº¤åª’ä½“å‡å°‘å­¤ç‹¬æ„Ÿï¼Œé€‚åº¦ä½¿ç”¨æé«˜ç¤¾äº¤æŠ€èƒ½ã€‚é—®é¢˜ï¼š1. ä¸»è¦è§‚ç‚¹ï¼Ÿ2. å†²çª/äº’è¡¥ï¼Ÿ3. æ•´åˆä¸¤è§‚ç‚¹ï¼Ÿ", "answer_type": "multi_text"},
    {"question": "æ¨¡ç³ŠæŒ‡ä»¤ï¼š'å¸®æˆ‘çœ‹çœ‹è¿™ä¸ªæŠ¥å‘Š'â€”â€”æå‡ºè‡³å°‘3ç§å¯èƒ½ç†è§£åŠå¯¹åº”å›å¤ã€‚", "answer_type": "ambiguous_request"},
    {"question": "å™ªå£°è¾“å…¥å¤„ç†ï¼šç”¨æˆ·ï¼š'æˆ‘æƒ³ä¹°å°ç”µè„‘ï¼Œä¸»è¦æ˜¯æ‰“æ¸¸æˆï¼Œé¢„ç®—5000-7000ï¼Œè¯·æ¨è' è¯·ï¼š1)æå–å…³é”®éœ€æ±‚ 2)è¯†åˆ«æ¨¡ç³Šç‚¹ 3)è¿½é—®ç¡®è®¤ 4)ç»™å‡ºæ¨èã€‚", "answer_type": "noisy_input"},
    {"question": "ä¸Šä¸‹æ–‡å®¹é”™ï¼šç”¨æˆ·è¯´ï¼š'å®ƒä¸å¥½ç”¨ã€‚'ï¼ˆæ— å‰æ–‡ï¼‰åˆ†æç”¨æˆ·è¡¨è¾¾é—®é¢˜ï¼Œç»™å‡ºå›åº”ç­–ç•¥ã€‚", "answer_type": "context_error"},
    {"question": "é€»è¾‘å®¹é”™ï¼šç”¨æˆ·ï¼š'ç”¨Pythonå†™æ’åºç®—æ³•ï¼Œä»å¤§åˆ°å°ï¼Œä¸è€ƒè™‘æ—¶é—´å¤æ‚åº¦ï¼Œæ”¯æŒå­—ç¬¦ä¸²ï¼Œå‘Šè¯‰æˆ‘ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªç®—æ³•' åˆ†æè¦æ±‚ä¸­çš„é€»è¾‘çŸ›ç›¾å’Œå†—ä½™ã€‚", "answer_type": "requirement_contradiction"},
    {"question": "è·¨è¯­è¨€å¤„ç†ï¼šç”¨æˆ·è¾“å…¥ï¼š'I want to buy ä¸€ä¸ª phoneï¼Œé¢„ç®— 2000-3000 yuan' åˆ†æè¾“å…¥ç‰¹ç‚¹å¹¶ç»™å‡ºå›ç­”ã€‚", "answer_type": "code_mixing"},
    {"question": "è¯­ä¹‰æ¶ˆæ­§ï¼š'ä»–å­¦ä¹ é›·é”‹å¥½æ¦œæ ·'â€”â€”å‡ ä¸ªå¯èƒ½è§£é‡Šï¼Ÿåˆ†åˆ«è¯´æ˜ã€‚", "answer_type": "word_sense"},
    {"question": "éšå–»ç†è§£ï¼š'ç”Ÿæ´»å°±åƒä¸€ç›’å·§å…‹åŠ›'â€”â€”è¡¨è¾¾ä»€ä¹ˆï¼Ÿä¸'ç”Ÿæ´»æ˜¯ä¸€åœºæ—…è¡Œ'æœ‰ä½•å¼‚åŒï¼Ÿ", "answer_type": "metaphor"},
    {"question": "æƒ…æ„Ÿåˆ†æï¼šåˆ†æå¥å­æƒ…æ„Ÿå¼ºåº¦(1-10)å’Œç±»å‹ï¼š1.è¿™äº§å“è¿˜è¡Œå§ 2.ç®€ç›´å¤ªåƒåœ¾äº† 3.å‹‰å¼ºèƒ½ç”¨ 4.è¶…ä¹æƒ³è±¡çš„å¥½ 5.ä¸€èˆ¬èˆ¬", "answer_type": "sentiment"},
    {"question": "è®½åˆºè¯†åˆ«ï¼š'å“‡ï¼Œä½ çœŸæ˜¯èªæ˜ç»é¡¶å•Šï¼ŒæŠŠç®€å•çš„äº‹æƒ…æè¿™ä¹ˆå¤æ‚ï¼'åˆ†æçœŸæ­£å«ä¹‰å’Œè¯´è¯è€…æ€åº¦ã€‚", "answer_type": "sarcasm"},
    {"question": "æŒ‡ä»£æ¶ˆè§£ï¼š'å¼ ä¼Ÿå‘Šè¯‰ä»–å¦»å­ä»–è¦å‡ºå·®ä¸‰å¤©ã€‚ä»–ç¬¬äºŒå¤©å°±èµ°äº†ã€‚'åˆ†æ'ä»–'åˆ†åˆ«æŒ‡ä»£è°ï¼Ÿæœ‰ä»€ä¹ˆæ­§ä¹‰ï¼Ÿ", "answer_type": "coreference"},
]

CODE_QUESTIONS = [
    {"question": "ã€LRUç¼“å­˜ã€‘ç”¨Pythonå®ç°LRUç¼“å­˜ï¼Œgetå’Œputæ–¹æ³•ï¼Œæ—¶é—´å¤æ‚åº¦O(1)ã€‚", "answer_type": "lru_cache"},
    {"question": "ã€å‘å¸ƒè®¢é˜…ã€‘ç”¨JSå®ç°å‘å¸ƒ-è®¢é˜…æ¨¡å¼ï¼Œsubscribeã€unsubscribeã€publishæ–¹æ³•ã€‚", "answer_type": "pub_sub"},
    {"question": "ã€æ„ŸçŸ¥æœºã€‘ç”¨Pythonå®ç°å•å±‚æ„ŸçŸ¥æœºç¥ç»ç½‘ç»œï¼ŒåŒ…å«å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ã€‚", "answer_type": "perceptron"},
    {"question": "ã€å¤æ‚SQLã€‘å‘˜å·¥è¡¨employees(id, name, department_id, salary, hire_date)ã€‚æŸ¥è¯¢å„éƒ¨é—¨å·¥èµ„æœ€é«˜çš„å‰3åï¼ŒæŒ‰éƒ¨é—¨æ’åºã€‚", "answer_type": "complex_sql"},
    {"question": "ã€çº¢é»‘æ ‘ã€‘ç”¨Pythonå®ç°çº¢é»‘æ ‘æ’å…¥æ“ä½œï¼Œæ­£ç¡®æ—‹è½¬å’Œå˜è‰²ã€‚", "answer_type": "red_black_tree"},
    {"question": "ã€Bugä¿®å¤ã€‘ä»¥ä¸‹Pythonä»£ç æœ‰bugï¼Œæ‰¾å‡ºå¹¶ä¿®å¤ï¼šdef find_max(numbers): max_num=0; for i in range(len(numbers)): if numbers[i]>max_num: max_num=numbers[i]; return max_num; print(find_max([-1,-5,-3])) æœŸæœ›-1", "answer_type": "bug_fix"},
    {"question": "ã€å¼‚æ­¥ä¿®å¤ã€‘ä¿®å¤ä»¥ä¸‹Promiseä»£ç ï¼šasync function fetchData() { const response = await fetch('/api/data'); const data = await response.json(); return data; } fetchData().then(data => console.log(data));", "answer_type": "async_fix"},
    {"question": "ã€ç«æ€ä¿®å¤ã€‘Goä»£ç å­˜åœ¨ç«æ€æ¡ä»¶ï¼švar counter int; func increment() { counter++ }; func main() { for i:=0; i<1000; i++ { go increment() }; time.Sleep(time.Second); fmt.Println(counter) }", "answer_type": "race_condition"},
    {"question": "ã€SQLä¿®å¤ã€‘ä¿®å¤SQLï¼šSELECT department, AVG(salary) FROM employees WHERE AVG(salary)>5000 GROUP BY department; è¯´æ˜é—®é¢˜å¹¶æä¾›æ­£ç¡®å†™æ³•ã€‚", "answer_type": "sql_fix"},
    {"question": "ã€æ•ˆç‡ä¼˜åŒ–ã€‘ä¼˜åŒ–ä»£ç ï¼šimport multiprocessing; def process_item(item): return item*2; data=[1,2,3,4,5]; with multiprocessing.Pool(4) as pool: results=pool.map(process_item, data)", "answer_type": "optimization_fix"},
    {"question": "ã€å­—å…¸æ ‘ã€‘ç”¨Pythonå®ç°Trieæ ‘ï¼Œinsertã€searchã€startsWithæ–¹æ³•ã€‚", "answer_type": "trie"},
    {"question": "ã€å †æ’åºã€‘ç”¨Pythonæ‰‹å†™å †æ’åºè¿‡ç¨‹ï¼Œä¸èƒ½ç”¨heapqåº“ã€‚", "answer_type": "heap_sort"},
    {"question": "ã€äºŒåˆ†å˜ä½“ã€‘åœ¨æ—‹è½¬æ•°ç»„[4,5,6,7,0,1,2]ä¸­æŸ¥æ‰¾0ï¼Œè¿”å›ç´¢å¼•æˆ–-1ã€‚", "answer_type": "binary_search"},
    {"question": "ã€æ‹“æ‰‘æ’åºã€‘ç”¨Pythonå®ç°Kahnç®—æ³•æ‹“æ‰‘æ’åºï¼Œè¿”å›ç»“æœæˆ–æ£€æµ‹ç¯ã€‚", "answer_type": "topological_sort"},
    {"question": "ã€LCSå­—ç¬¦ä¸²ã€‘ç”¨Pythonå®ç°æœ€é•¿å…¬å…±å­åºåˆ—ç®—æ³•ï¼Œè¿”å›LCSå­—ç¬¦ä¸²ï¼ˆä¸ä»…é•¿åº¦ï¼‰ã€‚", "answer_type": "lcs_string"},
    {"question": "ã€Token Bucketã€‘ç”¨Pythonå®ç°Token Bucketé™æµå™¨ï¼Œé™é€Ÿ100è¯·æ±‚/ç§’ï¼Œå…è®¸çªå‘ã€‚", "answer_type": "rate_limiter"},
    {"question": "ã€ç”Ÿäº§è€…-æ¶ˆè´¹è€…ã€‘ç”¨Pythonå®ç°ï¼Œé˜Ÿåˆ—çº¿ç¨‹å®‰å…¨ï¼Œæœ€å¤§å®¹é‡100ã€‚", "answer_type": "producer_consumer"},
    {"question": "ã€æ­£åˆ™åŒ¹é…ã€‘åŒ¹é…ä¸­å›½æ‰‹æœºå·ï¼ˆ1å¼€å¤´ï¼Œ3-9ä½ï¼Œå…±11ä½ï¼‰ã€‚éªŒè¯ï¼š13800138000, 18912345678, 12345678901, 1501234567, +8615012345678", "answer_type": "regex_mobile"},
    {"question": "ã€Pandaså¤„ç†ã€‘è¯»å–CSV 'sales.csv'ï¼Œè®¡ç®—æ¯æœˆæ€»é”€å”®é¢ï¼Œæ‰¾å‡ºæœ€é«˜äº§å“ç±»åˆ«ï¼Œæè¿°æœˆåº¦è¶‹åŠ¿ã€‚", "answer_type": "pandas"},
    {"question": "ã€å¤æ‚åº¦åˆ†æã€‘åˆ†æä»¥ä¸‹ä»£ç æ—¶é—´/ç©ºé—´å¤æ‚åº¦å¹¶ä¼˜åŒ–ï¼šdef duplicate(arr): for i in range(len(arr)): for j in range(i+1,len(arr)): if arr[i]==arr[j]: return True; return False", "answer_type": "complexity_analysis"},
]

print(f"[{datetime.now().strftime('%H:%M:%S')}] [INIT] é¢˜ç›®åº“åŠ è½½å®Œæˆï¼šæ¨ç†{len(REASONING_QUESTIONS)}é¢˜ï¼Œè¯­è¨€{len(LANGUAGE_QUESTIONS)}é¢˜ï¼Œä»£ç {len(CODE_QUESTIONS)}é¢˜ï¼Œå…±{len(REASONING_QUESTIONS)+len(LANGUAGE_QUESTIONS)+len(CODE_QUESTIONS)}é¢˜", flush=True)


# ==================== è¯„æµ‹å™¨ ====================

class LLMEvaluator:
    def __init__(self, api_url: str, model_name: str):
        self.api_url = api_url.rstrip('/')
        self.model_name = model_name
        self.results = {
            "reasoning": {"scores": [], "response_times": []},
            "language": {"scores": [], "response_times": []},
            "code": {"scores": [], "response_times": []}
        }

    def call_api(self, messages: List[Dict], timeout: int = 300) -> Tuple[str, float]:
        ollama_payload = {
            "model": self.model_name,
            "messages": messages,
            "stream": False,
            "options": {"temperature": 0.7}
        }
        start_time = time.time()
        try:
            response = requests.post(self.api_url, json=ollama_payload, timeout=timeout)
            response.raise_for_status()
            data = response.json()
            if "message" in data:
                content = data["message"].get("content", str(data))
            elif "choices" in data and len(data["choices"]) > 0:
                content = data["choices"][0]["message"]["content"]
            else:
                content = str(data)
        except Exception as e:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {e}")
        return content, time.time() - start_time

    def evaluate_response(self, question: Dict, response: str) -> int:
        score = 0
        answer_type = question.get("answer_type", "")
        response_lower = response.lower()
        if len(response) > 100:
            score += 20
        if "æ­¥éª¤" in response or "because" in response_lower or "therefore" in response_lower:
            score += 20
        if any(kw in response_lower for kw in ["è§£", "ç­”æ¡ˆ", "result", "solution", "åˆ†æ"]):
            score += 15
        if "def " in response_lower or "function" in response_lower or "select" in response_lower:
            score += 20
        if "return" in response_lower or "where" in response_lower or "class" in response_lower:
            score += 15
        if any(kw in response_lower for kw in ["é”™è¯¯", "ä¸å¯¹", "é—®é¢˜", "ä¿®å¤", "fix", "bug"]):
            score += 10
        return min(max(score, 0), 100)

    def test_category(self, questions: List[Dict], category_key: str, category_name: str) -> Dict:
        total_score = 0
        response_times = []
        total_q = len(questions)
        for idx, q in enumerate(questions, 1):
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®ç®€æ´åœ°å›ç­”é—®é¢˜ã€‚"},
                {"role": "user", "content": q['question']}
            ]
            try:
                response, response_time = self.call_api(messages)
                response_times.append(response_time)
                score = self.evaluate_response(q, response)
                total_score += score
                self.results[category_key]["scores"].append(score)
                self.results[category_key]["response_times"].append(response_time)
                print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] [{category_name}] {idx}/{total_q} | å¾—åˆ†:{score:3d} | è€—æ—¶:{response_time:6.1f}s | ç´¯è®¡å¾…æµ‹:{total_q-idx}", flush=True)
            except Exception as e:
                print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] [{category_name}] {idx}/{total_q} | é”™è¯¯: {e}", flush=True)
                response_times.append(0)
        avg_score = total_score / len(questions) if questions else 0
        return {"average_score": avg_score, "average_response_time": sum(response_times)/len(response_times) if response_times else 0}

    def evaluate(self) -> Dict:
        results = {}
        print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] å¼€å§‹æµ‹è¯•æ¨ç†èƒ½åŠ›({len(REASONING_QUESTIONS)}é¢˜)...", flush=True)
        results["reasoning"] = self.test_category(REASONING_QUESTIONS, "reasoning", "æ¨ç†")
        print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] æ¨ç†å®Œæˆ: {results['reasoning']['average_score']:.1f}/100", flush=True)
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] å¼€å§‹æµ‹è¯•è¯­è¨€èƒ½åŠ›({len(LANGUAGE_QUESTIONS)}é¢˜)...", flush=True)
        results["language"] = self.test_category(LANGUAGE_QUESTIONS, "language", "è¯­è¨€")
        print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] è¯­è¨€å®Œæˆ: {results['language']['average_score']:.1f}/100", flush=True)
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] å¼€å§‹æµ‹è¯•ä»£ç èƒ½åŠ›({len(CODE_QUESTIONS)}é¢˜)...", flush=True)
        results["code"] = self.test_category(CODE_QUESTIONS, "code", "ä»£ç ")
        print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] ä»£ç å®Œæˆ: {results['code']['average_score']:.1f}/100", flush=True)
        
        total_score = sum(r["average_score"] for r in results.values()) / 3
        print(f"[{datetime.now().strftime('%H:%M:%S')}] [{self.model_name}] æµ‹è¯•å®Œæˆ | ç»¼åˆ:{total_score:.1f}/100", flush=True)
        
        return {
            "model": self.model_name,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "reasoning": results["reasoning"],
            "language": results["language"],
            "code": results["code"],
            "overall_score": total_score,
            "avg_response_time": sum(r["average_response_time"] for r in results.values()) / 3
        }


MODELS = [
    "qwen2.5:14b",
    "deepseek-r1:14b",
    "qwen3:14b",
    "erwan2/DeepSeek-R1-Distill-Qwen-14B:latest",
    "gemma3:27b",
    "deepseek-r1:32b",
    "qwq:32b"
]


def generate_html_report(all_results: List[Dict]) -> str:
    sorted_results = sorted(all_results, key=lambda x: x["overall_score"], reverse=True)
    def get_color(score):
        if score >= 90: return "#4CAF50"
        if score >= 80: return "#8BC34A"
        if score >= 70: return "#FFEB3B"
        if score >= 60: return "#FF9800"
        return "#f44336"
    def get_level(score):
        if score >= 90: return "Sçº§ - å“è¶Š"
        if score >= 80: return "Açº§ - ä¼˜ç§€"
        if score >= 70: return "Bçº§ - è‰¯å¥½"
        if score >= 60: return "Cçº§ - ä¸€èˆ¬"
        return "Dçº§ - å¾…æå‡"
    rows = ""
    for i, r in enumerate(sorted_results, 1):
        rows += f"""
        <tr>
            <td>{i}</td>
            <td><strong>{r['model']}</strong></td>
            <td style="background:{get_color(r['reasoning']['average_score'])};color:white;font-weight:bold">{r['reasoning']['average_score']:.1f}</td>
            <td style="background:{get_color(r['language']['average_score'])};color:white;font-weight:bold">{r['language']['average_score']:.1f}</td>
            <td style="background:{get_color(r['code']['average_score'])};color:white;font-weight:bold">{r['code']['average_score']:.1f}</td>
            <td style="background:{get_color(r['overall_score'])};color:white;font-weight:bold;font-size:1.1em">{r['overall_score']:.1f}</td>
            <td>{r['avg_response_time']:.2f}s</td>
            <td><strong>{get_level(r['overall_score'])}</strong></td>
        </tr>"""
    html = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>å¤§æ¨¡å‹æ™ºå•†è¯„æµ‹æŠ¥å‘Šï¼ˆå¼ºåŒ–ç‰ˆï¼‰</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 40px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}
        .container {{ max-width: 1400px; margin: 0 auto; background: white; padding: 40px; border-radius: 20px; box-shadow: 0 20px 60px rgba(0,0,0,0.3); }}
        h1 {{ color: #333; text-align: center; font-size: 2.5em; margin-bottom: 10px; }}
        .subtitle {{ text-align: center; color: #666; margin-bottom: 40px; }}
        .stats {{ display: flex; justify-content: space-around; margin: 30px 0; flex-wrap: wrap; gap: 20px; }}
        .stat-box {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px 40px; border-radius: 15px; text-align: center; min-width: 150px; }}
        .stat-box .val {{ font-size: 2.5em; font-weight: bold; }}
        .stat-box .lbl {{ font-size: 1em; opacity: 0.9; }}
        table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
        th, td {{ padding: 12px 8px; text-align: center; border: 1px solid #ddd; font-size: 0.95em; }}
        th {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }}
        .footer {{ text-align: center; color: #999; margin-top: 30px; padding-top: 20px; border-top: 1px solid #eee; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ§  å¤§æ¨¡å‹æ™ºå•†è¯„æµ‹æŠ¥å‘Šï¼ˆå¼ºåŒ–ç‰ˆï¼‰</h1>
        <p class="subtitle">æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | å…±{len(REASONING_QUESTIONS)+len(LANGUAGE_QUESTIONS)+len(CODE_QUESTIONS)}é¢˜/æ¨¡å‹ | 60é¢˜Ã—7æ¨¡å‹</p>
        <div class="stats">
            <div class="stat-box"><div class="val">{len(all_results)}</div><div class="lbl">æµ‹è¯•æ¨¡å‹</div></div>
            <div class="stat-box"><div class="val">{sum(r['overall_score'] for r in all_results)/len(all_results):.1f}</div><div class="lbl">å¹³å‡å¾—åˆ†</div></div>
            <div class="stat-box"><div class="val">{max(r['overall_score'] for r in all_results):.1f}</div><div class="lbl">æœ€é«˜å¾—åˆ†</div></div>
            <div class="stat-box"><div class="val">{min(r['overall_score'] for r in all_results):.1f}</div><div class="lbl">æœ€ä½å¾—åˆ†</div></div>
        </div>
        <table>
            <thead><tr><th>æ’å</th><th>æ¨¡å‹</th><th>æ¨ç†(20)</th><th>è¯­è¨€(20)</th><th>ä»£ç (20)</th><th>ç»¼åˆ</th><th>å“åº”</th><th>ç­‰çº§</th></tr></thead>
            <tbody>{rows}</tbody>
        </table>
        <div class="footer">
            <p>ğŸ“š å¼ºåŒ–ç‰ˆæµ‹è¯•ï¼šæ¨ç†(æ•°å­¦+é€»è¾‘+è§„åˆ’)ã€è¯­è¨€(è¯­æ³•+é˜…è¯»+å®¹é”™)ã€ä»£ç (ç¼–å†™+ä¿®å¤+ç®—æ³•)</p>
        </div>
    </div>
</body>
</html>"""
    return html


def main():
    api_url = "http://localhost:11434/api/chat"
    all_results = []
    
    print("="*80, flush=True)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] [START] å¼€å§‹å¼ºåŒ–ç‰ˆè¯„æµ‹", flush=True)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] [CONFIG] API: {api_url}", flush=True)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] [CONFIG] æ¨¡å‹æ•°: {len(MODELS)}", flush=True)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] [CONFIG] æ¯æ¨¡å‹é¢˜ç›®æ•°: æ¨ç†{len(REASONING_QUESTIONS)} + è¯­è¨€{len(LANGUAGE_QUESTIONS)} + ä»£ç {len(CODE_QUESTIONS)} = {len(REASONING_QUESTIONS)+len(LANGUAGE_QUESTIONS)+len(CODE_QUESTIONS)}é¢˜", flush=True)
    print("="*80, flush=True)
    
    for model_idx, model in enumerate(MODELS, 1):
        print(f"\n[{datetime.now().strftime('%H:%M:%S')}] [MODEL {model_idx}/{len(MODELS)}] å¼€å§‹æµ‹è¯•æ¨¡å‹: {model}", flush=True)
        try:
            evaluator = LLMEvaluator(api_url, model)
            result = evaluator.evaluate()
            all_results.append(result)
        except Exception as e:
            print(f"\n[{datetime.now().strftime('%H:%M:%S')}] [ERROR] æ¨¡å‹ {model} æµ‹è¯•å¤±è´¥: {e}", flush=True)
            all_results.append({"model": model, "overall_score": 0, "avg_response_time": 0, "reasoning": {"average_score": 0}, "language": {"average_score": 0}, "code": {"average_score": 0}})
    
    print(f"\n[{datetime.now().strftime('%H:%M:%S')}] [GENERATING] ç”ŸæˆHTMLæŠ¥å‘Š...", flush=True)
    html = generate_html_report(all_results)
    with open("llm_evaluation_enhanced.html", "w", encoding="utf-8") as f:
        f.write(html)
    
    print("\n" + "="*80, flush=True)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] [COMPLETE] è¯„æµ‹å®Œæˆï¼", flush=True)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] [OUTPUT] æŠ¥å‘Šæ–‡ä»¶: llm_evaluation_enhanced.html", flush=True)
    print("="*80, flush=True)
    
    print("\nğŸ† ç»¼åˆæ’è¡Œæ¦œ:", flush=True)
    for i, r in enumerate(sorted(all_results, key=lambda x: x["overall_score"], reverse=True), 1):
        print(f"  {i}. {r['model']}: {r['overall_score']:.1f}/100", flush=True)


if __name__ == "__main__":
    main()
